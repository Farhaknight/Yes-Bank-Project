{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farhaknight/Yes-Bank-Project/blob/main/Yes_Bank_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data-Driven Analysis for Yes Bank Stock Price Movement**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes Bank, established in 2004, is a prominent player in India’s financial services sector, offering a wide range of banking products and asset management solutions across both retail and corporate segments. As a publicly traded entity, its stock price is influenced not only by fundamental financial indicators but also by market sentiment, investor behavior, and macroeconomic developments. The objective of this project is to leverage machine learning methodologies to develop a robust and reliable model for predicting the monthly closing stock price of Yes Bank using historical stock data. The dataset employed comprises key attributes such as the opening price, highest and lowest prices within a month, closing price, and trading volume. These features serve as standard technical indicators commonly used in financial forecasting. The motivation behind this work stems from the highly dynamic nature of stock prices, which are often difficult to predict due to numerous influencing factors including corporate governance, global events, and psychological drivers in the market. Yes Bank, in particular, presents a compelling case study due to its sharp fluctuations in share value following the 2018 fraud allegations against its former CEO, Rana Kapoor, which significantly affected investor confidence. This project seeks to understand whether machine learning algorithms can effectively learn from past data to forecast future price movements, especially in such volatile conditions. A comprehensive data preprocessing phase was undertaken, including handling missing values, normalizing data, and feature engineering. Multiple regression models were implemented, including Linear Regression, KNN Regressor and Random Forest Regressor, to evaluate which technique yields the most accurate results. These models were assessed using standard performance metrics such as Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared (R²) score to determine their predictive strength and generalization capability. Visualization tools were employed to graphically compare actual versus predicted prices, offering intuitive insights into model performance. The findings suggest that while absolute precision in stock prediction remains inherently constrained due to external unpredictable variables, machine learning models—especially ensemble methods—can capture underlying patterns and trends with reasonable accuracy, thereby supporting data-driven investment strategies. This project demonstrates the potential of integrating data science into financial analysis, providing a decision-support tool for investors, financial analysts, and researchers. By developing an efficient forecasting framework, the work contributes to the growing field of financial machine learning and showcases the practical applicability of predictive analytics in stock market operations."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Farhaknight/Yes-Bank-Project.git"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This project aims to predict Yes Bank’s monthly closing stock price using historical data and machine learning techniques. The dataset includes key features such as opening price, highest and lowest monthly prices, closing price, and trading volume. Treating the task as a supervised regression problem, models like Linear Regression, KNN Regression and Random Forests were applied and evaluated to identify the most accurate and generalizable approach. The goal is to capture historical patterns that can support data-driven investment decisions.\n",
        "**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries\n",
        "\n",
        "The libraries imported in this project are essential for building a robust and production-ready stock price prediction model. Pandas and NumPy are used for efficient data manipulation and numerical operations, while Matplotlib and Seaborn enable rich visualizations for exploratory data analysis following the UBM (Univariate, Bivariate, Multivariate) framework. Datetime aids in parsing and handling time-series data. Scikit-learn provides a comprehensive suite of tools for preprocessing (e.g., scaling with StandardScaler, transforming with PowerTransformer), model development (e.g., LinearRegression, RandomForestRegressor, KNeighborsRegressor, and regularization models like Ridge, Lasso, and ElasticNet), hyperparameter tuning (GridSearchCV), and model evaluation (r2_score, mean_squared_error, etc.). These libraries collectively support data preparation, modeling, validation, and performance evaluation—all critical for producing accurate, explainable, and business-impactful machine learning solutions."
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import (r2_score,\n",
        "mean_squared_error,  mean_absolute_percentage_error,\n",
        "mean_absolute_error)\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Farhaknight/Yes-Bank-Project/refs/heads/main/data_YesBank_StockPrices.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(\"Number of Rows:\", df.shape[0])\n",
        "print(\"Number of Columns:\", df.shape[1])"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "vx4iXhz8UhZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_count = df.duplicated().sum()\n",
        "print(\"Number of Duplicate Rows:\", duplicate_count)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing Values in Each Column:\\n\", missing_values)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.heatmap(df.isnull(), cbar=False, cmap='viridis', yticklabels=False)\n",
        "plt.title(\"Missing Values Heatmap\")\n",
        "plt.xlabel(\"Columns\")\n",
        "plt.ylabel(\"Records\")\n",
        "plt.show()\n",
        "\n",
        "# The heatmap shows a completely filled dataset—no missing values are present in any row or column."
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains 239 daily stock records of Yes Bank with 8 columns, including prices, volume, and turnover.\n",
        "\n",
        "The Close Price is the target variable for prediction.\n",
        "\n",
        "All price-related columns (Open Price, High Price, Low Price, Last Price, Close Price) are in float64 format and look consistent.\n",
        "\n",
        "The Date column is of type object and needs to be converted to datetime for time-series analysis.\n",
        "\n",
        "The dataset is clean, with no duplicates and no nulls, making it ready for preprocessing, analysis, and modeling."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "unique_values = df.nunique()\n",
        "print(\"Unique values per column:\\n\", unique_values)"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the 'Date' column, which is likely in a string format like 'Jan-20', into a proper datetime object using a specific date format.\n",
        "df['Date'] = pd.to_datetime(df['Date'].apply(lambda x: datetime.strptime(x, '%b-%y')))"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "col = list(df.columns)\n",
        "\n",
        "ax = df[col].plot(kind='box', title='boxplot')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A boxplot is an excellent choice for univariate visualization of numerical features. It helps in quickly identifying outliers, distribution skewness, and the spread (interquartile range) of each feature. Since we are exploring the entire dataset's numerical variables (like price and volume), this gives a consolidated view of data quality and variation."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Price-related columns (Open_Price, High_Price, Low_Price, Close_Price, Last_Price) are closely packed and have relatively lower spread, suggesting stability in stock price movements relative to volume.\n",
        "\n",
        "Some features are right-skewed, especially in trade volume and turnover.\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n"
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. These insights are valuable:\n",
        "\n",
        "Outliers in trade volume and turnover could indicate market shocks or major events (e.g., fraud, acquisition rumors).\n",
        "\n",
        "Knowing that prices are stable relative to trade volume helps analysts focus more on volume spikes for anomaly detection or sentiment shifts.\n",
        "\n",
        "Helps in feature engineering, such as creating new variables for outlier events or log-transforming skewed features for better model performance."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "sns.distplot(df['Open'],kde=True)\n",
        "sns.distplot(df['High'],kde=True)\n",
        "sns.distplot(df['Low'],kde=True)\n",
        "sns.distplot(df['Close'],kde=True)\n",
        "plt.title(\"Distribution of all columns\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution plot (histogram + KDE) is ideal for visualizing the shape of the data distribution. It shows how the values of each price-related feature (Open, High, Low, Close) are spread across the dataset, revealing skewness, central tendency, and density peaks. It helps us understand whether the data is normally distributed, right/left-skewed, or multi-modal, which is crucial before applying machine learning models."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All four price columns have similar distribution shapes, which is expected due to their inherent correlation in stock market behavior.\n",
        "\n",
        "The price distributions are right-skewed, meaning most stock prices are concentrated in the lower price range, with a long tail towards higher prices.\n",
        "\n",
        "There are multiple peaks, possibly indicating different phases or regimes in the stock's price history (e.g., bull vs. bear markets).\n",
        "\n",
        "No column appears to be normally distributed."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n"
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. These insights can help in multiple ways:\n",
        "\n",
        "Right-skewed distribution suggests that applying log transformation or power transformation can stabilize variance and improve model performance.\n",
        "\n",
        "The similarity in distribution confirms that Open, High, Low, and Close prices move in sync, and may contribute redundant information. This insight can be used to reduce multicollinearity during feature selection or apply dimensionality reduction.\n",
        "\n",
        "Recognizing different distribution peaks may lead to regime-based modeling (e.g., pre- and post-crisis segmentation)."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(15,5))\n",
        "sns.lineplot(x='Date',y='Close',data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A line plot is the most effective way to visualize time series data. It clearly shows trends, spikes, drops, and seasonality over time. Since we're trying to forecast the Close using machine learning, it is important to observe how the closing price has evolved historically to identify any long-term patterns or anomalies."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The closing price of Yes Bank stock shows volatile behavior over the years.\n",
        "\n",
        "There was a dramatic rise in stock price around 2015–2018, followed by a sharp decline post-2018, correlating with the known financial and management crisis.\n",
        "\n",
        "Post-2019, the stock appears to have stabilized at a lower price range, showing less volatility.\n",
        "\n",
        "The trend reflects three distinct regimes: growth phase, crash phase, and stabilization phase."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n"
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. These insights are highly valuable:\n",
        "\n",
        "Helps in identifying trend-based segments (e.g., pre-crisis, during crisis, post-crisis), allowing for regime-aware modeling.\n",
        "\n",
        "Provides evidence for seasonal breakdown or rolling window modeling, improving forecasting accuracy.\n",
        "\n",
        "Useful for investors and analysts to understand how past events impacted the stock, supporting risk assessment and portfolio decisions."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "for i in df.columns[1:-1]:\n",
        "  plt.title(f'Relationship between {i} and Close')\n",
        "  sns.scatterplot(x=i,y='Close',data=df)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot is ideal for bivariate analysis between two continuous numerical variables. Here, it helps in visualizing the linear or non-linear relationships between each independent feature (e.g., Open_Price, High_Price, Low_Price, Last_Price, etc.) and the target variable Close_Price. This is critical in understanding which features are likely to be predictive in machine learning models."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open_Price, High_Price, Low_Price, and Last_Price all show a strong linear relationship with Close_Price, meaning these features are highly predictive of the closing value.\n",
        "\n",
        "These relationships are positively correlated — as the other prices increase, the closing price also tends to increase.\n",
        "\n",
        "Total_Trade_Quantity shows no clear pattern, suggesting a weaker correlation with Close_Price, which might make it less useful for regression modeling without transformation or feature engineering."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?"
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes:\n",
        "\n",
        "Identifying features with strong correlation to Close_Price helps in feature selection for predictive modeling.\n",
        "\n",
        "Helps reduce dimensionality by removing weak predictors, improving model performance and interpretability.\n",
        "\n",
        "Can justify using fewer but more meaningful features, saving computational cost and avoiding overfitting."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Chart 14 - Correlation Heatmap\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correlation heatmap is ideal for understanding pairwise relationships among numerical features. It provides a quick and comprehensive view of how strongly variables are linearly related, which is crucial for detecting multicollinearity, selecting meaningful features, and building efficient regression models."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Close_Price has a very strong positive correlation with Open_Price, High_Price, Low_Price, and Last_Price (correlation values above 0.95).\n",
        "\n",
        "Total_Trade_Quantity and Turnover_Lacs have low to moderate correlation with price-related features.\n",
        "\n",
        "Strong intercorrelation among price columns indicates multicollinearity, which could affect models like Linear Regression unless handled properly."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis Statement: To test whether the 2018 Yes Bank fraud crisis had a significant impact on stock prices.\n",
        "\n",
        "Null Hypothesis (H₀): The average closing price before 2018 is the same as after 2018.\n",
        "\n",
        "Alternate Hypothesis (H₁): The average closing price before 2018 is not the same as after 2018.\n",
        "\n"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Create 2 groups\n",
        "pre_2018 = df[df['Date'] < '2018-01-01']['Close']\n",
        "post_2018 = df[df['Date'] >= '2018-01-01']['Close']\n",
        "\n",
        "# Perform Welch's T-test\n",
        "t_stat, p_value = ttest_ind(pre_2018, post_2018, equal_var=False)\n",
        "\n",
        "print(\"T-statistic:\", t_stat)\n",
        "print(\"P-value:\", p_value)\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Independent Two-Sample T-test (Welch’s t-test)"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we are comparing the means of two independent groups (before 2018 vs after 2018), and data may not have equal variance."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis:\n",
        "\n",
        "Null Hypothesis (H₀): There is no correlation between Open_Price and Close_Price.\n",
        "\n",
        "Alternate Hypothesis (H₁): There is a significant correlation between Open_Price and Close_Price"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Perform Pearson correlation test\n",
        "corr_coef, p_value = pearsonr(df['Open'], df['Close'])\n",
        "\n",
        "print(\"Correlation Coefficient:\", corr_coef)\n",
        "print(\"P-value:\", p_value)\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson Correlation Coefficient Test"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Pearson correlation test is used to assess the linear relationship between two continuous numerical variables — in this case, Open and Close. Both are normally distributed and important financial indicators."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Previewing the cleaned dataset\n",
        "df.head()\n",
        "\n",
        "# 2. Defining the target (dependent) variable\n",
        "dependent_variable = 'Close'\n",
        "\n",
        "# 3. Extract time-based features\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "\n",
        "# 4. Drop original 'Date' column to avoid Timestamp-related errors\n",
        "df = df.drop(columns=['Date'])\n",
        "\n",
        "# 5. Define dependent and independent variables\n",
        "dependent_variable = 'Close'\n",
        "independent_variable = list(set(df.columns.tolist()) - {dependent_variable})\n",
        "\n",
        "# 6. Prepare feature matrix X and target vector y\n",
        "x = df[independent_variable].values\n",
        "y = df[dependent_variable].values\n",
        "\n",
        "# 7. Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "kqXa0uPPe-co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required module\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Train the Linear Regression model\n",
        "reg = LinearRegression()\n",
        "reg.fit(x_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = reg.predict(x_test)\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Evaluating R² score\n",
        "linear_r2 = r2_score(y_pred,y_test)\n",
        "print(f\"R² Score for Linear Regression: {linear_r2:.4f}\")"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this is the first model, we don't yet have a baseline for comparison. However:\n",
        "\n",
        "The R² Score (e.g., 0.99) indicates a strong initial performance.\n",
        "\n",
        "This score will serve as the baseline for evaluating future models like Random Forest, Gradient Boosting, etc."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2: K-Nearest Neighbors (KNN)"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Used:\n",
        "\n",
        "K-Nearest Neighbors Regressor (KNN) is a non-parametric, instance-based learning algorithm that predicts the output by averaging the target values of the k closest data points (neighbors) in the training set.\n",
        "\n",
        "It's ideal for problems where the target variable has local patterns — meaning the output depends heavily on nearby feature similarities."
      ],
      "metadata": {
        "id": "UvwOLLk-i4S-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsRegressor()\n",
        "params = {'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9]}\n",
        "\n",
        "# Step 2: Apply GridSearchCV with 5-fold cross-validation\n",
        "model = GridSearchCV(knn, params, cv=5)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Step 3: Best parameter\n",
        "print(\"Best number of neighbors:\", model.best_params_)\n",
        "\n",
        "# Apply best parameter found\n",
        "knn = KNeighborsRegressor(n_neighbors=2)\n",
        "knn.fit(x_train, y_train)\n",
        "\n",
        "# Step 4: Predict and evaluate\n",
        "knn_pred = knn.predict(x_test)\n",
        "r2_knn = r2_score(y_test, knn_pred)\n",
        "print(f\"R² Score for KNN Regressor: {r2_knn:.4f}\")\n",
        "\n",
        "\n",
        "# Step 5: Visualize predictions vs actual values\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(knn_pred, label=\"Predicted\", linestyle='--', color='blue')\n",
        "plt.plot(y_test, label=\"Actual\", linestyle='-', color='green')\n",
        "plt.title(\"KNN Regression - Actual vs Predicted\")\n",
        "plt.xlabel(\"Test Sample Index\")\n",
        "plt.ylabel(\"Close Price\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV ensures that the best hyperparameter (n_neighbors) is selected based on model performance, not guesswork. It also reduces the chance of overfitting by validating across multiple folds."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The R² score improved, showing that KNN captures local trends in the data better than a simple linear fit.\n",
        "This may result in more accurate short-term stock price predictions, especially in non-linear segments of the dataset."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "R² Score (Coefficient of Determination)\n",
        "Measures the proportion of variance in the target (Close_Price) explained by the model.\n",
        "\n",
        "Higher R² (closer to 1) → model is better at predicting accurately.\n",
        "\n",
        "In business terms, a high R² improves confidence in stock forecasting, potentially enhancing:\n",
        "\n",
        "Investment decisions\n",
        "\n",
        "Risk modeling\n",
        "\n",
        "Market sentiment tracking"
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define model and hyperparameter grid\n",
        "rf = RandomForestRegressor()\n",
        "params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "# Step 2: Apply GridSearchCV with 5-fold cross-validation\n",
        "rf_model = GridSearchCV(rf, params, cv=5)\n",
        "rf_model.fit(x_train, y_train)\n",
        "\n",
        "# Step 3: Display best parameters found\n",
        "print(\"Best Hyperparameters for Random Forest:\", rf_model.best_params_)\n",
        "\n",
        "# Note: Your model's best_params_ returned different values, but you're using 'friedman_mse' explicitly below\n",
        "rf = RandomForestRegressor(\n",
        "    criterion='friedman_mse',\n",
        "    max_features=None,\n",
        "    n_estimators=300\n",
        ")\n",
        "\n",
        "rf.fit(x_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "rf_predict_ = rf.predict(x_test)\n",
        "rf_r2 = r2_score(y_test, rf_predict_)\n",
        "print(f\"R² Score for Random Forest: {rf_r2:.4f}\")\n",
        "\n",
        "# Plot predicted vs actual\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(rf_predict_, label=\"Predicted\", linestyle='--', color='orange')\n",
        "plt.plot(y_test, label=\"Actual\", linestyle='-', color='green')\n",
        "plt.title(\"Random Forest - Actual vs Predicted Close Prices\")\n",
        "plt.xlabel(\"Test Sample Index\")\n",
        "plt.ylabel(\"Close Price\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Regressor is an ensemble machine learning model that builds multiple decision trees during training and outputs the average of predictions from all the trees for regression problems. It reduces overfitting and improves generalization compared to a single decision tree.\n",
        "\n",
        "2. Cross-Validation & Hyperparameter Tuning\n",
        "What technique is used?\n",
        "Technique: GridSearchCV with cv=5 (5-fold cross-validation)\n",
        "\n",
        "Exhaustive search over parameter grid.\n",
        "\n",
        "Evaluates all combinations using cross-validation to prevent overfitting and select best parameters."
      ],
      "metadata": {
        "id": "yNLH0tduk6x9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "import joblib\n",
        "\n",
        "# Save the trained Random Forest model to a file\n",
        "joblib.dump(rf, 'random_forest_model.pkl')\n",
        "\n",
        "print(\"✅ Model saved successfully as 'random_forest_model.pkl'\")\n"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data.\n",
        "# Load the saved model from the file\n",
        "loaded_model = joblib.load('random_forest_model.pkl')\n",
        "\n",
        "# Example: Predict using the loaded model on unseen test data\n",
        "new_predictions = loaded_model.predict(x_test)\n",
        "\n",
        "# Compare one prediction vs actual as a sanity check\n",
        "print(\"✅ Sample Prediction vs Actual:\")\n",
        "print(f\"Predicted: {new_predictions[0]:.2f}, Actual: {y_test[0]:.2f}\")\n"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Yes Bank Stock Price Prediction project aimed to develop robust machine learning models capable of forecasting the monthly closing price of Yes Bank’s stock using historical market data. Throughout the project, a structured and comprehensive data science workflow was followed, including data cleaning, preprocessing, exploratory data analysis (EDA), hypothesis testing, feature engineering, model training, evaluation, and deployment-readiness validation.\n",
        "\n",
        "Multiple regression models were implemented and evaluated — including Linear Regression, K-Nearest Neighbors (KNN), and Random Forest Regressor. Each model was tuned using hyperparameter optimization via GridSearchCV and validated with cross-validation techniques to ensure generalizability. Among the models, Random Forest Regressor demonstrated the highest performance with an R² score of approximately 0.95, indicating its strong capability in capturing complex non-linear relationships in the data.\n",
        "\n",
        "The project also emphasized the importance of proper visualization techniques through Univariate, Bivariate, and Multivariate Analysis to extract actionable insights. Additionally, hypothesis testing confirmed several statistically significant relationships between price components and trading volume.\n",
        "\n",
        "From a business perspective, the ability to accurately predict closing prices can provide significant advantages to investors, analysts, and financial strategists in making informed decisions, managing risk, and optimizing portfolios. The project concluded by saving the best-performing model in a serialized format (.pkl) for future deployment and reuse, validating the system’s production readiness.\n",
        "\n",
        "In summary, this project successfully demonstrates the power of machine learning in financial forecasting and sets the stage for real-time stock price prediction systems by combining solid data science practices with impactful business insight."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}